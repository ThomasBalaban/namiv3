# Save as: nami/main.py
import uvicorn
import asyncio
from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field
from typing import Dict, Any, Optional

import sys
import threading
import os
import shutil
import subprocess
import time
import requests
import json
import re
import atexit
from pathlib import Path

from nami.input_systems.priority_core import ConversationState
from nami.bot_core import ask_question, BOTNAME
from nami.twitch_integration import init_twitch_bot, send_to_twitch_sync
from nami.input_systems import (
    init_priority_system,
    shutdown_priority_system,
    process_console_command,
)

from nami.tts_utils.content_filter import process_response_for_content
from nami.director_process_manager import start_director_process, stop_director_process
from nami.director_connector import (
    start_connector_thread, 
    stop_connector, 
    send_bot_reply,
    notify_speech_started,
    notify_speech_finished
)

from nami.config import (
    NGROK_AUTH_ENABLED, 
    NGROK_AUTH_USERNAME, 
    NGROK_AUTH_PASSWORD,
    NGROK_INSPECT,
    SECURITY_NOTIFICATIONS
)

try:
    from nami.input_funnel.input_funnel import InputFunnel
    input_funnel_available = True
except ImportError:
    input_funnel_available = False
    print("InputFunnel module not found, will use traditional priority system")

try:
    from nami.tts_utils.tts_engine import text_to_speech_file
    from nami.tts_utils.audio_player import play_audio_file
    tts_available = True
except ImportError:
    tts_available = False
    text_to_speech_file = None
    play_audio_file = None

global_input_funnel = None
ngrok_process = None

# Thread-safe event to prevent Nami from talking over herself
nami_is_busy = threading.Event()
nami_is_busy.clear()

# --- INTERJECTION SERVER ---
interjection_app = FastAPI()
INTERJECTION_PORT = 8000

possible_paths = [
    Path("audio_effects"),
    Path(__file__).parent.parent / "audio_effects",
    Path(__file__).parent / "audio_effects"
]

audio_effects_path = None
for path in possible_paths:
    if path.exists() and path.is_dir():
        audio_effects_path = path.resolve()
        break

if audio_effects_path:
    print(f"‚úÖ Found audio effects directory at: {audio_effects_path}")
    interjection_app.mount("/audio_effects", StaticFiles(directory=str(audio_effects_path)), name="audio_effects")


class InterjectionPayload(BaseModel):
    content: str
    priority: float
    source_info: Dict[str, Any] = Field(default_factory=dict)

@interjection_app.post("/funnel/interject")
async def receive_interjection(payload: InterjectionPayload):
    global global_input_funnel
    
    # [FIX] Strict gating: If busy, ignore everything. No whitelist.
    if nami_is_busy.is_set():
        return {"status": "ignored", "message": "Nami is currently talking or thinking."}

    if global_input_funnel:
        # Lock the system immediately to prevent overlapping commands
        nami_is_busy.set()
        print(f"‚úÖ Accepted Command from Director: {payload.content[:50]}...")
        global_input_funnel.add_input(
            content=payload.content,
            priority=payload.priority,
            source_info=payload.source_info
        )
        return {"status": "success", "message": "Command received."}
    else:
        return {"status": "error", "message": "Nami funnel not ready."}

def run_interjection_server():
    uvicorn.run(interjection_app, host="0.0.0.0", port=INTERJECTION_PORT, log_level="warning")

def start_interjection_server_thread():
    server_thread = threading.Thread(target=run_interjection_server, daemon=True, name="InterjectionServer")
    server_thread.start()

def start_ngrok_tunnel():
    global ngrok_process
    try:
        response = requests.get("http://localhost:4040/api/tunnels", timeout=1)
        tunnels = response.json()
        if tunnels.get("tunnels"):
            tunnel = tunnels["tunnels"][0]
            if "8000" in tunnel.get("config", {}).get("addr", ""):
                return tunnel["public_url"]
    except:
        pass

    ngrok_path = shutil.which("ngrok")
    if not ngrok_path:
        return None
        
    try:
        cmd = [ngrok_path, "http", str(INTERJECTION_PORT)]
        if not NGROK_INSPECT:
            cmd.append("--inspect=false")
        cmd.append("--log=stdout")
        
        ngrok_process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        time.sleep(5)
        
        for attempt in range(5):
            try:
                response = requests.get("http://localhost:4040/api/tunnels", timeout=2)
                tunnels = response.json()
                if tunnels.get("tunnels"):
                    return tunnels["tunnels"][0]["public_url"]
            except:
                pass
            time.sleep(2)
        return None
    except:
        return None

def stop_ngrok():
    global ngrok_process
    if ngrok_process:
        ngrok_process.terminate()
        try: ngrok_process.wait(timeout=5)
        except subprocess.TimeoutExpired: ngrok_process.kill()
        ngrok_process = None

class FunnelResponseHandler:
    def __init__(self, generation_func=None, playback_func=None):
        self.generation_func = generation_func
        self.playback_func = playback_func

    def handle_response(self, response, prompt_details, source_info):
        """
        Processes the bot's response, handles filtering, updates the UI,
        sends to Twitch, and manages the TTS playback lifecycle.
        """
        # [FIX] Ensure we always unlock nami_is_busy even if response is empty
        if not response:
            print("‚ö†Ô∏è No response generated by bot. Releasing lock.")
            nami_is_busy.clear()
            from nami.input_systems.input_handlers import priority_system
            if priority_system:
                priority_system.set_state(ConversationState.IDLE)
            return
        
        # Process content through filters to get versions for TTS, Twitch, and UI
        filtered_content = process_response_for_content(response)
        tts_version = filtered_content['tts_version']
        twitch_version = filtered_content['twitch_version']
        ui_version = filtered_content['ui_version']
        is_censored = filtered_content['is_censored']
        # Extract the specific trigger word for the Director Engine UI
        reason = filtered_content.get('censorship_reason')

        if is_censored:
            print(f"\n[BOT - CENSORED] Reason: {reason}")
            print(f"Sending to TTS: {tts_version}")
        else:
            print(f"\n[BOT] {tts_version}")
        
        # Send details to Director Engine, including the specific censorship reason
        send_bot_reply(
            reply_text=ui_version, 
            prompt_text=prompt_details or "", 
            is_censored=is_censored,
            censorship_reason=reason,
            filtered_area=filtered_content.get('filtered_area')
        )

        # Handle Twitch integration
        try:
            source = source_info.get('source')
            if source in ['TWITCH_MENTION', 'DIRECT_MICROPHONE'] or (source and source.startswith('DIRECTOR_')):
                username = source_info.get('username')
                if source == 'TWITCH_MENTION' and username:
                    twitch_response = f"@{username} {twitch_version}"
                else:
                    twitch_response = twitch_version
                send_to_twitch_sync(twitch_response)
        except Exception as e:
            print(f"Twitch sending failed: {e}")

        # Update local state to BUSY while processing/speaking
        from nami.input_systems.input_handlers import priority_system
        if priority_system:
            priority_system.set_state(ConversationState.BUSY)

        # Handle TTS Generation and Playback
        if self.generation_func and self.playback_func:
            try:
                notify_speech_started() # Tell Director to stop interjecting
                audio_filename = self.generation_func(tts_version)
                
                if audio_filename:
                    def playback_with_notification(filename):
                        try:
                            self.playback_func(filename)
                        finally:
                            # Notify Director that speech is done and release local locks
                            notify_speech_finished()
                            nami_is_busy.clear()
                            if priority_system:
                                priority_system.set_state(ConversationState.IDLE)
                    
                    threading.Thread(target=playback_with_notification, args=(audio_filename,), daemon=True).start()
                else:
                    # Cleanup if generation failed
                    print("‚ùå TTS Generation failed. Cleaning up.")
                    nami_is_busy.clear()
                    notify_speech_finished()
                    if priority_system:
                        priority_system.set_state(ConversationState.IDLE)
            except Exception as e:
                print(f"Error in TTS lifecycle: {e}")
                nami_is_busy.clear()
                notify_speech_finished()
        else:
            # Unlock immediately if no audio system is active
            nami_is_busy.clear()
            if priority_system:
                priority_system.set_state(ConversationState.IDLE)
                
def console_input_loop():
    print(f"{BOTNAME} is ready.")
    while True:
        try:
            command = input("You: ")
            if process_console_command(command):
                break
        except Exception:
            break

def main():
    global global_input_funnel
    
    print("\n" + "="*60)
    print("üåä NAMI V3 (The Body) - Starting Up...")
    print("="*60)

    if not start_director_process():
        return
    
    start_interjection_server_thread()
    start_connector_thread()
    time.sleep(3) 
    
    if tts_available:
        ngrok_url = start_ngrok_tunnel()
        if ngrok_url:
            os.environ["NAMI_AUDIO_URL"] = f"{ngrok_url}/audio_effects"
            atexit.register(stop_ngrok)

    use_funnel = input_funnel_available
    if use_funnel:
        funnel_handler = FunnelResponseHandler(
            generation_func=text_to_speech_file if tts_available else None,
            playback_func=play_audio_file if tts_available else None
        )
        input_funnel = InputFunnel(
            bot_callback=ask_question,
            response_handler=funnel_handler.handle_response,
            min_prompt_interval=2
        )
        global_input_funnel = input_funnel
        init_priority_system(funnel_instance=input_funnel)
    else:
        init_priority_system(enable_bot_core=True)

    init_twitch_bot(funnel=global_input_funnel)

    print("\n‚úÖ Nami is Online.")
    
    try:
        console_input_loop()
    except KeyboardInterrupt:
        pass
    finally:
        if global_input_funnel:
            global_input_funnel.stop()
        shutdown_priority_system()
        stop_director_process()
        stop_ngrok()
        stop_connector()

if __name__ == "__main__":
    main()